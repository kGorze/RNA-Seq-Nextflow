/*
 * RNA-Seq Nextflow Pipeline Configuration
 */

// Default parameters
params {
    // Input/output options
    reads          = null
    genome         = null
    gtf            = null
    outdir         = './results'
    
    // Pipeline options
    aligner        = 'star'    // Options: 'star', 'hisat2', 'salmon'
    paired_end     = true
    strandedness   = 'unstranded' // Options: 'unstranded', 'forward', 'reverse'
    
    // QC options
    skip_qc        = false
    skip_trimming  = false
    
    // Resource allocation
    max_memory     = '16.GB'
    max_cpus       = 8
    max_time       = '24.h'
    
    // Differential expression
    design         = null      // Path to design file for differential expression
    contrasts      = null      // Path to contrasts file for differential expression
    
    // Test profile options
    test           = false
    
    // Help
    help           = false
}

// Process resource defaults
process {
    cpus   = { check_max( 2    * task.attempt, 'cpus'   ) }
    memory = { check_max( 4.GB * task.attempt, 'memory' ) }
    time   = { check_max( 2.h  * task.attempt, 'time'   ) }
    
    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
    maxRetries    = 3
    maxErrors     = '-1'
}

// Function to ensure that resource requirements don't exceed available resources
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "WARNING: Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "WARNING: Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "WARNING: Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Profiles
profiles {
    standard {
        process.executor = 'local'
    }
    
    docker {
        docker.enabled = true
        docker.runOptions = '-u $(id -u):$(id -g)'
        singularity.enabled = false
    }
    
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        docker.enabled = false
    }
    
    test {
        params.test = true
        process.executor = 'local'
        process {
            cpus = 1
            memory = '1.GB'
            maxForks = 4  // Allow parallel execution
        }
    }
    
    aws {
        aws.region = 'us-east-1'
        aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
        process.executor = 'awsbatch'
        process.queue = 'nextflow-batch-queue'
    }
}

// Manifest
manifest {
    name            = 'RNA-Seq Nextflow Pipeline'
    author          = 'Author'
    homePage        = 'https://github.com/username/rnaseq-nextflow-pipeline'
    description     = 'A reproducible RNA-Seq analysis pipeline implemented in Nextflow'
    mainScript      = 'main.nf'
    nextflowVersion = '>=21.10.0'
    version         = '1.0.0'
}

// Enable DSL2
nextflow.enable.dsl = 2

// Logging configuration
trace {
    enabled = true
    file = "${params.outdir}/pipeline_trace.txt"
    overwrite = true
    fields = ['task_id', 'hash', 'native_id', 'name', 'status', 'exit', 'submit', 'duration', 'realtime', 'cpus', '%cpu', 'memory', '%mem', 'rss', 'vmem', 'peak_rss', 'peak_vmem', 'rchar', 'wchar']
}

dag {
    enabled = true
    file = "${params.outdir}/pipeline_dag.svg"
    overwrite = true
}

report {
    enabled = true
    file = "${params.outdir}/pipeline_report.html"
    overwrite = true
}

// Control log files
log {
    enabled = true
    file = '.nextflow.log'
    overwrite = true
}

// Custom completion handler
workflow.onComplete {
    // Get the trace file
    def traceFile = new File("${params.outdir}/pipeline_trace.txt")
    if (traceFile.exists()) {
        // Skip header
        def lines = traceFile.readLines()[1..-1]
        
        // Group by module and calculate total duration
        def moduleStats = [:]
        lines.each { line ->
            def fields = line.split('\t')
            def name = fields[3] // name field
            def duration = fields[7].toLong() // duration field
            def module = name.split(':')[0]
            
            moduleStats[module] = moduleStats.getOrDefault(module, 0) + duration
        }
        
        // Sort modules by total duration
        def sortedModules = moduleStats.sort { -it.value }
        
        println "\nModule Execution Time Summary:"
        println "=============================="
        sortedModules.each { module, duration ->
            def minutes = duration / 60000
            println String.format("%-20s : %.2f minutes", module, minutes)
        }
        println "=============================="
    }
}
